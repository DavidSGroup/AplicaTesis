{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854667d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import music21 as m21\n",
    "from music21 import converter\n",
    "KERN_DATASET_PATH = \"C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/3 - Preprocessing dataset for melody generation pt 1/code/deutschl/test/\"\n",
    "#KERN_DATASET_PATH = \"C:/Users/Davids/Documents/Cueca Marco Aplicativo/Datos/test/\"\n",
    "SAVE_DIR = \"C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/3 - Preprocessing dataset for melody generation pt 1/code/deutschl/dataset/\"\n",
    "# Resto del código de las funciones y definiciones\n",
    "# Definición de load_songs_in_kern, has_acceptable_durations, transpose, preprocess\n",
    "from music21 import environment\n",
    "environment.set('musicxmlPath', 'C:\\\\Program Files\\\\MuseScore 3\\\\bin\\\\MuseScore3.exe')\n",
    "from music21 import environment\n",
    "\n",
    "# Configurar la ruta del ejecutable de MuseScore para la conversión a PNG\n",
    "environment.set(\"musescoreDirectPNGPath\", \"C:\\\\Program Files\\\\MuseScore 3\\\\bin\\\\MuseScore3.exe\")\n",
    "import subprocess\n",
    "from music21 import environment\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fedb17e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add99dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_FILE_DATASET = \"file_dataset\"\n",
    "MAPPING_PATH = \"mapping.json\"\n",
    "SEQUENCE_LENGTH = 64\n",
    "#SEQUENCE_LENGTH = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b554a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_PATH = \"mapping.json\"\n",
    "SEQUENCE_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5567e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# durations are expressed in quarter length\n",
    "ACCEPTABLE_DURATIONS = [\n",
    "    0.25, # 16th note\n",
    "    0.5, # 8th note\n",
    "    0.75,\n",
    "    1.0, # quarter note\n",
    "    1.5,\n",
    "    2, # half note\n",
    "    3,\n",
    "    4 # whole note\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a0b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio temporal personalizado configurado en C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/3 - Preprocessing dataset for melody generation pt 1/code/deutschl/otro/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from music21 import environment\n",
    "\n",
    "# Directorio temporal personalizado\n",
    "custom_temp_dir = 'C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/3 - Preprocessing dataset for melody generation pt 1/code/deutschl/otro/'  # Ruta a tu directorio temporal\n",
    "\n",
    "# Función para configurar el directorio temporal personalizado\n",
    "def set_temp_dir():\n",
    "    # Elimina el directorio si existe\n",
    "    shutil.rmtree(custom_temp_dir, ignore_errors=True)\n",
    "    # Crea el directorio si no existe\n",
    "    os.makedirs(custom_temp_dir)\n",
    "\n",
    "    # Establece el directorio temporal personalizado en tu entorno de music21\n",
    "    environment.set('directoryScratch', custom_temp_dir)\n",
    "    print(f\"Directorio temporal personalizado configurado en {custom_temp_dir}\")\n",
    "\n",
    "# Llamada a la función para configurar el directorio temporal\n",
    "set_temp_dir()\n",
    "\n",
    "# Aquí puedes continuar con el resto de tu código, utilizando el directorio temporal configurado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de62d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_m21(mObj, width=None, height=None):\n",
    "    # Save defaults\n",
    "    author = m21.defaults.author\n",
    "    title = m21.defaults.title\n",
    "    # Remove them\n",
    "    m21.defaults.author = None\n",
    "    m21.defaults.title = None\n",
    "    \n",
    "    us = m21.environment.UserSettings() \n",
    "    scratchPath = pathlib.Path(us['directoryScratch'])\n",
    "    fname = mObj.write() #  This writes a temp musicXML file and returns the name\n",
    "    p_mxml = pathlib.Path(fname)\n",
    "    p_out = p_mxml.with_suffix(\".png\")\n",
    "    # Create command string\n",
    "    musescorePath = us['musescoreDirectPNGPath']\n",
    "    musescoreRun = '\"' + str(musescorePath) + '\" ' + str(p_mxml) + ' -o  ' + str(p_out) + ' -T 0 '\n",
    "    #os.system(musescoreRun)\n",
    "    subprocess.run(musescoreRun, shell=True)\n",
    "    png_files = scratchPath.glob(\"*.png\")\n",
    "    base_name = p_mxml.stem\n",
    "    # Restore defaults\n",
    "    m21.defaults.author = author\n",
    "    m21.defaults.title = author\n",
    "    for png in png_files:\n",
    "        if png.match(base_name + \"*\"):\n",
    "            return Image(filename=str(png), width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791f61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_songs_in_kern(dataset_path):\n",
    "    \"\"\"Loads all kern pieces in dataset using music21.\n",
    "\n",
    "    :param dataset_path (str): Path to dataset\n",
    "    :return songs (list of m21 streams): List containing all pieces\n",
    "    \"\"\"\n",
    "    songs = []\n",
    "\n",
    "    # go through all the files in dataset and load them with music21\n",
    "    for path, subdirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "\n",
    "            # consider only kern files\n",
    "            if file[-3:] == \"krn\":\n",
    "                song = m21.converter.parse(os.path.join(path, file))\n",
    "                songs.append(song)\n",
    "     # Imprime la lista de canciones\n",
    "    #print(\"Lista de canciones cargadas:\")\n",
    "    #for song in songs:\n",
    "     #   print(song)  # Imprime cada canción\n",
    "\n",
    "    return songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff5b33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset_path):\n",
    "\n",
    "    # load folk songs\n",
    "    print(\"Loading songs...\")\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs.\")\n",
    "    \n",
    "    for i, song in enumerate(songs):\n",
    "        # filter out songs that have non-acceptable durations\n",
    "        if not has_acceptable_durations(song, ACCEPTABLE_DURATIONS):\n",
    "            continue\n",
    "\n",
    "        # transpose songs to Cmaj/Amin\n",
    "        song = transpose(song)\n",
    "\n",
    "        # encode songs with music time series representation\n",
    "        encoded_song = encode_song(song)#esto no lo usamos\n",
    "\n",
    "        # save songs to text file\n",
    "        save_path = os.path.join(SAVE_DIR, str(i))\n",
    "        with open(save_path, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b881e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_acceptable_durations(song, acceptable_durations):\n",
    "    \"\"\"Boolean routine that returns True if piece has all acceptable duration, False otherwise.\n",
    "\n",
    "    :param song (m21 stream):\n",
    "    :param acceptable_durations (list): List of acceptable duration in quarter length\n",
    "    :return (bool):\n",
    "    \"\"\"\n",
    "    for note in song.flatten().notesAndRests:\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561c889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(song):\n",
    "    \"\"\"Transposes song to C maj/A min\n",
    "\n",
    "    :param piece (m21 stream): Piece to transpose\n",
    "    :return transposed_song (m21 stream):\n",
    "    \"\"\"\n",
    "\n",
    "    # get key from the song\n",
    "    parts = song.getElementsByClass(m21.stream.Part)\n",
    "    measures_part0 = parts[0].getElementsByClass(m21.stream.Measure)\n",
    "    key = measures_part0[0][4]\n",
    "\n",
    "    # estimate key using music21\n",
    "    if not isinstance(key, m21.key.Key):\n",
    "        key = song.analyze(\"key\")\n",
    "\n",
    "    # get interval for transposition. E.g., Bmaj -> Cmaj\n",
    "    if key.mode == \"major\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
    "    elif key.mode == \"minor\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\"))\n",
    "\n",
    "    # transpose song by calculated interval\n",
    "    tranposed_song = song.transpose(interval)\n",
    "    return tranposed_song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408dcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_song(song, time_step=0.25):\n",
    "    \"\"\"Converts a score into a time-series-like music representation. Each item in the encoded list represents 'min_duration'\n",
    "    quarter lengths. The symbols used at each step are: integers for MIDI notes, 'r' for representing a rest, and '_'\n",
    "    for representing notes/rests that are carried over into a new time step. Here's a sample encoding:\n",
    "\n",
    "        [\"r\", \"_\", \"60\", \"_\", \"_\", \"_\", \"72\" \"_\"]\n",
    "\n",
    "    :param song (m21 stream): Piece to encode\n",
    "    :param time_step (float): Duration of each time step in quarter length\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_song = []\n",
    "\n",
    "    for event in song.flatten().notesAndRests:\n",
    "\n",
    "        # handle notes\n",
    "        if isinstance(event, m21.note.Note):\n",
    "            symbol = event.pitch.midi # 60\n",
    "        # handle rests\n",
    "        elif isinstance(event, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "\n",
    "        # convert the note/rest into time series notation\n",
    "        steps = int(event.duration.quarterLength / time_step)\n",
    "        for step in range(steps):\n",
    "\n",
    "            # if it's the first time we see a note/rest, let's encode it. Otherwise, it means we're carrying the same\n",
    "            # symbol in a new time step\n",
    "            if step == 0:\n",
    "                encoded_song.append(symbol)\n",
    "            else:\n",
    "                encoded_song.append(\"_\")\n",
    "\n",
    "    # cast encoded song to str\n",
    "    encoded_song = \" \".join(map(str, encoded_song))\n",
    "\n",
    "    return encoded_song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a0d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        song = fp.read()\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce3b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_file_dataset(dataset_path, file_dataset_path, sequence_length):\n",
    "    \"\"\"Generates a file collating all the encoded songs and adding new piece delimiters.\n",
    "\n",
    "    :param dataset_path (str): Path to folder containing the encoded songs\n",
    "    :param file_dataset_path (str): Path to file for saving songs in single file\n",
    "    :param sequence_length (int): # of time steps to be considered for training\n",
    "    :return songs (str): String containing all songs in dataset + delimiters\n",
    "    \"\"\"\n",
    "\n",
    "    new_song_delimiter = \"/ \" * sequence_length\n",
    "    songs = \"\"\n",
    "\n",
    "    # load encoded songs and add delimiters\n",
    "    for path, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(path, file)\n",
    "            song = load(file_path)\n",
    "            songs = songs + song + \" \" + new_song_delimiter\n",
    "\n",
    "    # remove empty space from last character of string\n",
    "    songs = songs[:-1]\n",
    "\n",
    "    # save string that contains all the dataset\n",
    "    with open(file_dataset_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d250cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(songs, mapping_path):\n",
    "    \"\"\"Creates a json file that maps the symbols in the song dataset onto integers\n",
    "\n",
    "    :param songs (str): String with all songs\n",
    "    :param mapping_path (str): Path where to save mapping\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mappings = {}\n",
    "\n",
    "    # identify the vocabulary\n",
    "    songs = songs.split()\n",
    "    vocabulary = list(set(songs))\n",
    "\n",
    "    # create mappings\n",
    "    for i, symbol in enumerate(vocabulary):\n",
    "        mappings[symbol] = i\n",
    "\n",
    "    # save voabulary to a json file\n",
    "    with open(mapping_path, \"w\") as fp:\n",
    "        json.dump(mappings, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7bf47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_songs_to_int(songs):\n",
    "    int_songs = []\n",
    "\n",
    "    # load mappings\n",
    "    with open(MAPPING_PATH, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "\n",
    "    # transform songs string to list\n",
    "    songs = songs.split()\n",
    "\n",
    "    # map songs to int\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "\n",
    "    return int_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24bf0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_dataset\n"
     ]
    }
   ],
   "source": [
    "print(SINGLE_FILE_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e60a8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_sequences(sequence_length):\n",
    "    \"\"\"Create input and output data samples for training. Each sample is a sequence.\n",
    "\n",
    "    :param sequence_length (int): Length of each sequence. With a quantisation at 16th notes, 64 notes equates to 4 bars\n",
    "\n",
    "    :return inputs (ndarray): Training inputs\n",
    "    :return targets (ndarray): Training targets\n",
    "    \"\"\"\n",
    "\n",
    "    # load songs and map them to int\n",
    "    songs = load(SINGLE_FILE_DATASET)\n",
    "    #print(\"dat: \" ,songs)\n",
    "    int_songs = convert_songs_to_int(songs)\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    # generate the training sequences\n",
    "    num_sequences = len(int_songs) - sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:i+sequence_length])\n",
    "        targets.append(int_songs[i+sequence_length])\n",
    "\n",
    "    # one-hot encode the sequences\n",
    "    vocabulary_size = len(set(int_songs))\n",
    "    # inputs size: (# of sequences, sequence length, vocabulary size)\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes=vocabulary_size)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return inputs, targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca59a9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading songs...\n",
      "Loaded 100 songs.\n",
      "Secuencia de inputs:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "Secuencia de targets:\n",
      "[0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # load songs\n",
    "\n",
    "    #songs = load_songs_in_kern(KERN_DATASET_PATH)\n",
    "    #print(f\"Loaded {len(songs)} songs.\")\n",
    "    #song = songs[0]\n",
    "    \n",
    "    preprocess(KERN_DATASET_PATH)\n",
    "    songs = create_single_file_dataset(SAVE_DIR, SINGLE_FILE_DATASET, SEQUENCE_LENGTH)\n",
    "    create_mapping(songs, MAPPING_PATH)\n",
    "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
    "    # transpose song\n",
    "    #transposed_song = transpose(song)\n",
    "    #transposed_song.show()\n",
    "    print(\"Secuencia de inputs:\")\n",
    "    print(inputs)\n",
    "    print(\"\\nSecuencia de targets:\")\n",
    "    print(targets)    \n",
    "    #print(f\"Has acceptable duration? {has_acceptable_durations(song, ACCEPTABLE_DURATIONS)}\")\n",
    "\n",
    "    #song.show\n",
    "    #show_m21(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50befc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c858d06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 38)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               302080    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 38)                9766      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 311846 (1.19 MB)\n",
      "Trainable params: 311846 (1.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, None, 38), found shape=(None, 64, 18)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(SAVE_MODEL_PATH)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     train()\n",
      "Cell \u001b[1;32mIn[19], line 59\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(output_units, num_units, loss, learning_rate)\u001b[0m\n\u001b[0;32m     56\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(output_units, num_units, loss, learning_rate)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(inputs, targets, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[0;32m     62\u001b[0m model\u001b[38;5;241m.\u001b[39msave(SAVE_MODEL_PATH)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebctqdodi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Davids\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, None, 38), found shape=(None, 64, 18)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from preprocess import generate_training_sequences, SEQUENCE_LENGTH\n",
    "\n",
    "OUTPUT_UNITS = 38\n",
    "NUM_UNITS = [256]\n",
    "LOSS = \"sparse_categorical_crossentropy\"\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "SAVE_MODEL_PATH = \"model.h5\"\n",
    "\n",
    "\n",
    "def build_model(output_units, num_units, loss, learning_rate):\n",
    "    \"\"\"Builds and compiles model\n",
    "\n",
    "    :param output_units (int): Num output units\n",
    "    :param num_units (list of int): Num of units in hidden layers\n",
    "    :param loss (str): Type of loss function to use\n",
    "    :param learning_rate (float): Learning rate to apply\n",
    "\n",
    "    :return model (tf model): Where the magic happens :D\n",
    "    \"\"\"\n",
    "\n",
    "    # create the model architecture\n",
    "    input = keras.layers.Input(shape=(None, output_units))\n",
    "    x = keras.layers.LSTM(num_units[0])(input)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    output = keras.layers.Dense(output_units, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(input, output)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(output_units=OUTPUT_UNITS, num_units=NUM_UNITS, loss=LOSS, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"Train and save TF model.\n",
    "\n",
    "    :param output_units (int): Num output units\n",
    "    :param num_units (list of int): Num of units in hidden layers\n",
    "    :param loss (str): Type of loss function to use\n",
    "    :param learning_rate (float): Learning rate to apply\n",
    "    \"\"\"\n",
    "\n",
    "    # generate the training sequences\n",
    "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
    "\n",
    "    # build the network\n",
    "    model = build_model(output_units, num_units, loss, learning_rate)\n",
    "\n",
    "    # train the model\n",
    "    model.fit(inputs, targets, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # save the model\n",
    "    model.save(SAVE_MODEL_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b5294",
   "metadata": {},
   "source": [
    "# codigo de generando melodia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3346852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from preprocess import SEQUENCE_LENGTH, MAPPING_PATH\n",
    "\n",
    "#MAPPING_PATH = \"C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/5 - Preprocessing dataset for melody generation pt 3/mapping.json\"\n",
    "#SEQUENCE_LENGTH = 64\n",
    "#ruta=\"C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/6 - Preparing the training samples/model.h5\"\n",
    "ruta=\"C:/Users/Davids/Downloads/melody/generating-melodies-with-rnn-lstm-master/9 - Converting Generated Melodies to MIDI/model.h5\"\n",
    "class MelodyGenerator:\n",
    "    \"\"\"A class that wraps the LSTM model and offers utilities to generate melodies.\"\"\"\n",
    "\n",
    "    #def __init__(self, model_path=\"model.h5\"):\n",
    "    def __init__(self, model_path=ruta):\n",
    "        \"\"\"Constructor that initialises TensorFlow model\"\"\"\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "\n",
    "        with open(MAPPING_PATH, \"r\") as fp:\n",
    "            self._mappings = json.load(fp)\n",
    "\n",
    "        self._start_symbols = [\"/\"] * SEQUENCE_LENGTH\n",
    "    def generate_melody(self, seed, num_steps, max_sequence_length, temperature):\n",
    "        \"\"\"Generates a melody using the DL model and returns a midi file.\n",
    "\n",
    "        :param seed (str): Melody seed with the notation used to encode the dataset\n",
    "        :param num_steps (int): Number of steps to be generated\n",
    "        :param max_sequence_len (int): Max number of steps in seed to be considered for generation\n",
    "        :param temperature (float): Float in interval [0, 1]. Numbers closer to 0 make the model more deterministic.\n",
    "            A number closer to 1 makes the generation more unpredictable.\n",
    "\n",
    "        :return melody (list of str): List with symbols representing a melody\n",
    "        \"\"\"\n",
    "\n",
    "        # create seed with start symbols\n",
    "        seed = seed.split()\n",
    "        melody = seed\n",
    "        seed = self._start_symbols + seed\n",
    "\n",
    "        # map seed to int\n",
    "        seed = [self._mappings[symbol] for symbol in seed]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "\n",
    "            # limit the seed to max_sequence_length\n",
    "            seed = seed[-max_sequence_length:]\n",
    "\n",
    "            # one-hot encode the seed\n",
    "            onehot_seed = keras.utils.to_categorical(seed, num_classes=len(self._mappings))\n",
    "            # (1, max_sequence_length, num of symbols in the vocabulary)\n",
    "            #print(self._mappings)\n",
    "            onehot_seed = onehot_seed[np.newaxis, ...]\n",
    "\n",
    "            # make a prediction\n",
    "            probabilities = self.model.predict(onehot_seed)[0]\n",
    "            # [0.1, 0.2, 0.1, 0.6] -> 1\n",
    "            output_int = self._sample_with_temperature(probabilities, temperature)\n",
    "\n",
    "            # update seed\n",
    "            seed.append(output_int)\n",
    "\n",
    "            # map int to our encoding\n",
    "            output_symbol = [k for k, v in self._mappings.items() if v == output_int][0]\n",
    "\n",
    "            # check whether we're at the end of a melody\n",
    "            if output_symbol == \"/\":\n",
    "                break\n",
    "\n",
    "            # update melody\n",
    "            melody.append(output_symbol)\n",
    "\n",
    "        return melody\n",
    "    def _sample_with_temperature(self, probabilites, temperature):\n",
    "        \"\"\"Samples an index from a probability array reapplying softmax using temperature\n",
    "\n",
    "        :param predictions (nd.array): Array containing probabilities for each of the possible outputs.\n",
    "        :param temperature (float): Float in interval [0, 1]. Numbers closer to 0 make the model more deterministic.\n",
    "            A number closer to 1 makes the generation more unpredictable.\n",
    "\n",
    "        :return index (int): Selected output symbol\n",
    "        \"\"\"\n",
    "        predictions = np.log(probabilites) / temperature\n",
    "        probabilites = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "\n",
    "        choices = range(len(probabilites)) # [0, 1, 2, 3]\n",
    "        index = np.random.choice(choices, p=probabilites)\n",
    "\n",
    "        return index\n",
    "if __name__ == \"__main__\":\n",
    "    mg = MelodyGenerator()\n",
    "    seed = \"55 _ _ _ 60 _ _ _ 55 _ _ _ 55 _\"\n",
    "    melody = mg.generate_melody(seed, 500, SEQUENCE_LENGTH, 0.7)\n",
    "    print(melody)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42259d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
